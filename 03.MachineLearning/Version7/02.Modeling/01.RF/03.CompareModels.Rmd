---
title: "Performance of all classifier"
author: "Chao Tang"
date: 'Report created: `r Sys.Date()`'
output: 
  html_document: 
    code_folding: "hide"
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: false
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.align = 'center')
knitr::opts_knit$set(root.dir = "/mnt/raid61/Personal_data/tangchao/AANanopore")
knitr::opts_knit$set(base.dir = "/mnt/raid61/Personal_data/tangchao/AANanopore")
```

```{r required packages}
library(data.table)
library(ggplot2)
library(parallel)
library(caret)
library(doParallel)
library(pbapply)
library(patchwork)
library(multiROC)
library(pROC)
library(cowplot)
library(dummies)
library(Biostrings)
```

```{r}
Preds <- readRDS(file = "analysis/03.MachineLearning/Version7/02.Modeling/01.RF/02.CompareModels/Preds.Rds")
```

```{r}
cutoffList <- mclapply(Preds, function(res) {
  res[pred == true, Result := "Correct"]
  res[pred != true, Result := "Wrong"]
  cutoffList <- lapply(1:50/50, function(b) {
    merge(res[, .(Recovery = mean(Prob >= b)), by = Dataset], 
          res[Prob >= b, .(Accuracy = mean(Result == "Correct")), by = Dataset])
  })
  cutoffList <- data.table(Cutoff = rep(1:50/50, mapply(nrow, cutoffList)), do.call(rbind, cutoffList))
  cutoffList[, L := paste0("(", round(Recovery * 100, 1), ", ", round(Accuracy * 100, 1), ")")]
  return(cutoffList)
}, mc.cores = 6)

cutoffList <- data.table(Model = rep(paste0("RF", 1:6), mapply(nrow, cutoffList)), do.call(rbind, cutoffList))
```

# Test 

```{r}
mc_roc_Test <- list() 
for(i in 1:6) {
  x <- Preds[[i]][Dataset == "Test"]
  true_label1 <- dummies::dummy(x$true, sep = " ")
  true_label1 <- data.frame(true_label1)
  colnames(true_label1) <- gsub("true.", "", colnames(true_label1))
  colnames(true_label1) <- paste0(colnames(true_label1), "_true")
  
  pred_RF1 <- x[, names(x) %in% AMINO_ACID_CODE, with = F]
  colnames(pred_RF1) <- paste0(colnames(pred_RF1), "_pred_RF")

  final_RF1 <- cbind(true_label1, pred_RF1)
  roc_RF1 <- multiROC::multi_roc(final_RF1)
  pr_RF1 <- multiROC::multi_pr(final_RF1)

  plot_roc_RF1 <- data.table(Model = x[, unique(Model)], as.data.table(plot_roc_data(roc_RF1)))
  plot_pr_RF1 <- data.table(Model = x[, unique(Model)], as.data.table(plot_pr_data(pr_RF1)))
  mc_roc_Test[[i]] <- list(ROC = plot_roc_RF1, PR = plot_pr_RF1)
}
```

```{r}
mc_pr_Test <- lapply(mc_roc_Test, function(x) x[[2]])
mc_roc_Test <- lapply(mc_roc_Test, function(x) x[[1]])
```

## plot

```{r}
ROC_AUCs <- lapply(mc_roc_Test, function(x) {
  data.table(Curve = "ROC", Model = x[, unique(Model)], Macro = x[Group == "Macro", unique(AUC)], Micro = x[Group == "Micro", unique(AUC)])
})

PR_AUCs <- lapply(mc_pr_Test, function(x) {
  data.table(Curve = "PR", Model = x[, unique(Model)], Macro = x[Group == "Macro", unique(AUC)], Micro = x[Group == "Micro", unique(AUC)])
})
AUCs <- rbind(do.call(rbind, ROC_AUCs), do.call(rbind, PR_AUCs))
AUCs[, Model := gsub("Fit", "RF", Model)]
```

### ROC

```{r}
roc_mat <- lapply(mc_roc_Test, function(x) {
  set.seed(123)
  x[Group == "Macro"][sort(sample(.N, 1000))]
})
roc_mat <- do.call(rbind, roc_mat)
roc_mat[, Model := gsub("Fit", "RF", Model)]
```

```{r}
od <- AUCs[Curve == "ROC"][order(Macro, decreasing = T), Model]
roc_mat[, Model := factor(Model, levels = od)]
AUCs[, Model := factor(Model, levels = od)]
setkey(AUCs, Curve, Model)
```

```{r}
MoldeCols <- RColorBrewer::brewer.pal(n = 6, name = "Dark2")
names(MoldeCols) <- paste0("RF", 1:6)
```

```{r fig.width=6, fig.height=4}
ggplot(roc_mat, aes(x = 1 - Specificity, y = Sensitivity, colour = Model)) + 
  geom_path(size = 1) + 
  geom_text(data = AUCs[Curve == "ROC", ], mapping = aes(x = 0.75, y = 6:1/10, label = paste0("AUC = ", round(Macro, 4)))) +
  theme_bw(base_size = 15) + 
  scale_color_manual(values = MoldeCols) + 
  lims(x = c(0, 1), y = c(0, 1))
ggsave("./analysis/03.MachineLearning/Version7/02.Modeling/01.RF/02.CompareModels/Test_ROCs.pdf", width = 5.5, height = 4)
```

### PR

```{r}
pr_mat <- lapply(mc_pr_Test, function(x) {
  set.seed(123)
  x[Group == "Macro"][sort(sample(.N, 1000))]
})
pr_mat <- do.call(rbind, pr_mat)
pr_mat[, Model := gsub("Fit", "RF", Model)]
```

```{r}
od <- AUCs[Curve == "PR"][order(Macro, decreasing = T), Model]
pr_mat[, Model := factor(Model, levels = od)]
AUCs[, Model := factor(Model, levels = od)]
setkey(AUCs, Curve, Model)
```

```{r}
MoldeCols <- RColorBrewer::brewer.pal(n = 6, name = "Dark2")
names(MoldeCols) <- paste0("RF", 1:6)
```

```{r fig.width=6, fig.height=4}
ggplot(pr_mat, aes(x = Recall, y = Precision, colour = Model)) + 
  geom_path(size = 1) + 
  geom_text(data = AUCs[Curve == "PR", ], mapping = aes(x = 0.25, y = 6:1/10, label = paste0("AUC = ", round(Macro, 4)))) +
  theme_bw(base_size = 15) + 
  scale_color_manual(values = MoldeCols) + 
  lims(x = c(0, 1), y = c(0, 1))
ggsave("./analysis/03.MachineLearning/Version7/02.Modeling/01.RF/02.CompareModels/Test_PRCs.pdf", width = 5.5, height = 4)
```


# Validation 

```{r}
mc_roc_Valid <- list() 
for(i in 1:6) {
  x <- Preds[[i]][Dataset == "Validation"]
  true_label1 <- dummies::dummy(x$true, sep = " ")
  true_label1 <- data.frame(true_label1)
  colnames(true_label1) <- gsub("true.", "", colnames(true_label1))
  colnames(true_label1) <- paste0(colnames(true_label1), "_true")
  
  pred_RF1 <- x[, names(x) %in% AMINO_ACID_CODE, with = F]
  colnames(pred_RF1) <- paste0(colnames(pred_RF1), "_pred_RF")

  final_RF1 <- cbind(true_label1, pred_RF1)
  roc_RF1 <- multiROC::multi_roc(final_RF1)
  pr_RF1 <- multiROC::multi_pr(final_RF1)

  plot_roc_RF1 <- data.table(Model = x[, unique(Model)], as.data.table(plot_roc_data(roc_RF1)))
  plot_pr_RF1 <- data.table(Model = x[, unique(Model)], as.data.table(plot_pr_data(pr_RF1)))
  mc_roc_Valid[[i]] <- list(ROC = plot_roc_RF1, PR = plot_pr_RF1)
}
```

```{r}
mc_pr_Valid <- lapply(mc_roc_Valid, function(x) x[[2]])
mc_roc_Valid <- lapply(mc_roc_Valid, function(x) x[[1]])
```

## plot

```{r}
ROC_AUCs <- lapply(mc_roc_Valid, function(x) {
  data.table(Curve = "ROC", Model = x[, unique(Model)], Macro = x[Group == "Macro", unique(AUC)], Micro = x[Group == "Micro", unique(AUC)])
})

PR_AUCs <- lapply(mc_pr_Valid, function(x) {
  data.table(Curve = "PR", Model = x[, unique(Model)], Macro = x[Group == "Macro", unique(AUC)], Micro = x[Group == "Micro", unique(AUC)])
})
AUCs <- rbind(do.call(rbind, ROC_AUCs), do.call(rbind, PR_AUCs))
AUCs[, Model := gsub("Fit", "RF", Model)]
```

### ROC

```{r}
roc_mat <- lapply(mc_roc_Valid, function(x) {
  set.seed(123)
  x[Group == "Macro"][sort(sample(.N, 1000))]
})
roc_mat <- do.call(rbind, roc_mat)
roc_mat[, Model := gsub("Fit", "RF", Model)]
```

```{r}
od <- AUCs[Curve == "ROC"][order(Macro, decreasing = T), Model]
roc_mat[, Model := factor(Model, levels = od)]
AUCs[, Model := factor(Model, levels = od)]
setkey(AUCs, Curve, Model)
```

```{r}
MoldeCols <- RColorBrewer::brewer.pal(n = 6, name = "Dark2")
names(MoldeCols) <- paste0("RF", 1:6)
```

```{r fig.width=6, fig.height=4}
ggplot(roc_mat, aes(x = 1 - Specificity, y = Sensitivity, colour = Model)) + 
  geom_path(size = 1) + 
  geom_text(data = AUCs[Curve == "ROC", ], mapping = aes(x = 0.75, y = 6:1/10, label = paste0("AUC = ", round(Macro, 4)))) +
  theme_bw(base_size = 15) + 
  scale_color_manual(values = MoldeCols) + 
  lims(x = c(0, 1), y = c(0, 1))
ggsave("./analysis/03.MachineLearning/Version7/02.Modeling/01.RF/02.CompareModels/Valid_ROCs.pdf", width = 5.5, height = 4)
```

### PR

```{r}
pr_mat <- lapply(mc_pr_Valid, function(x) {
  set.seed(123)
  x[Group == "Macro"][sort(sample(.N, 1000))]
})
pr_mat <- do.call(rbind, pr_mat)
pr_mat[, Model := gsub("Fit", "RF", Model)]
```

```{r}
od <- AUCs[Curve == "PR"][order(Macro, decreasing = T), Model]
pr_mat[, Model := factor(Model, levels = od)]
AUCs[, Model := factor(Model, levels = od)]
setkey(AUCs, Curve, Model)
```

```{r}
MoldeCols <- RColorBrewer::brewer.pal(n = 6, name = "Dark2")
names(MoldeCols) <- paste0("RF", 1:6)
```

```{r fig.width=6, fig.height=4}
ggplot(pr_mat, aes(x = Recall, y = Precision, colour = Model)) + 
  geom_path(size = 1) + 
  geom_text(data = AUCs[Curve == "PR", ], mapping = aes(x = 0.25, y = 6:1/10, label = paste0("AUC = ", round(Macro, 4)))) +
  theme_bw(base_size = 15) + 
  scale_color_manual(values = MoldeCols) + 
  lims(x = c(0, 1), y = c(0, 1))
ggsave("./analysis/03.MachineLearning/Version7/02.Modeling/01.RF/02.CompareModels/Valid_PRCs.pdf", width = 5.5, height = 4)
```

```{r fig.width=8, fig.height=4.5}
library(ggrepel)
ggplot(cutoffList[Dataset %in% c("Test", "Validation")], aes(x = Recovery * 100, y = Accuracy * 100, colour = Model)) + 
  geom_line() + 
  theme_bw(base_size = 15) + 
  scale_x_reverse() + 
  labs(x = "Recovery (%)", y = "Accuracy (%)") + 
  theme(legend.position = "top") + 
  geom_point(data = cutoffList[Dataset %in% c("Test", "Validation") & Cutoff %in% c(c(7)/10)]) +
  geom_text_repel(data = cutoffList[Dataset %in% c("Test", "Validation") & Cutoff %in% c(c(7)/10)], aes(label = L)) + 
  scale_color_brewer(palette = "Dark2") + 
  facet_grid(~ Dataset) + 
  guides(colour = guide_legend(nrow = 1))
ggsave("analysis/03.MachineLearning/Version7/02.Modeling/01.RF/02.CompareModels/Cutoff_Recovery_Accuracy2.pdf", width = 8, height = 4.5)
```


```{r fig.width=8, fig.height=4.5}
library(ggpubr)
ggplot(cutoffList[Dataset %in% c("Test")], aes(x = Recovery * 100, y = Accuracy * 100, colour = Model)) + 
  geom_line() + 
  theme_bw(base_size = 15) + 
  scale_x_reverse() + 
  labs(x = "Recovery (%)", y = "Accuracy (%)") + 
  theme(legend.position = "top") + 
  geom_point(data = cutoffList[Dataset %in% c("Test") & Cutoff %in% c(c(7)/10)]) +
  geom_text(data = cutoffList[Dataset %in% c("Test") & Cutoff %in% c(c(7)/10)], aes(x = 25, y = seq(73, 88, 3), label = L)) + 
  scale_color_brewer(palette = "Dark2") + 
  facet_grid(~ Dataset) + 
  lims(y = c(70, 100)) + 
  guides(colour = guide_legend(nrow = 1)) -> p1

lg <- as_ggplot(get_legend(p1))
p1 <- p1 + theme(legend.position = "none")

ggplot(cutoffList[Dataset %in% c("Validation")], aes(x = Recovery * 100, y = Accuracy * 100, colour = Model)) + 
  geom_line() + 
  theme_bw(base_size = 15) + 
  scale_x_reverse() + 
  labs(x = "Recovery (%)", y = "Accuracy (%)") + 
  theme(legend.position = "top") + 
  geom_point(data = cutoffList[Dataset %in% c("Validation") & Cutoff %in% c(c(7)/10)]) +
  geom_text(data = cutoffList[Dataset %in% c("Validation") & Cutoff %in% c(c(7)/10)], aes(x = 25, y = seq(73, 88, 3), label = L)) + 
  scale_color_brewer(palette = "Dark2") + 
  facet_grid(~ Dataset) + 
  lims(y = c(70, 100)) + 
  guides(colour = guide_legend(nrow = 1)) -> p2
p2 <- p2 + theme(legend.position = "none")

lg / (p1 + p2) + plot_layout(heights = c(1, 9))
ggsave("analysis/03.MachineLearning/Version7/02.Modeling/01.RF/02.CompareModels/Cutoff_Recovery_Accuracy3.pdf", width = 8, height = 4.5)
```

```{r fig.width=3.5, fig.height=3.5}
cutoffList[, L := paste0(Model, L)]
```

```{r fig.width=3.5, fig.height=3.5}
ggplot(cutoffList[Dataset %in% c("Test")], aes(x = Recovery * 100, y = Accuracy * 100, colour = Model)) + 
  geom_line() + 
  theme_bw(base_size = 15) + 
  scale_x_reverse() + 
  labs(x = "Recovery (%)", y = "Accuracy (%)", title = "Test set") + 
  theme(legend.position = "top") + 
  geom_point(data = cutoffList[Dataset %in% c("Test") & Cutoff %in% c(c(7)/10)]) +
  geom_text(data = cutoffList[Dataset %in% c("Test") & Cutoff %in% c(c(7)/10)], aes(x = 25, y = seq(73, 88, 3), label = L)) + 
  scale_color_brewer(palette = "Dark2") + 
  lims(y = c(70, 100)) + 
  guides(colour = "none")
ggsave("analysis/03.MachineLearning/Version7/02.Modeling/01.RF/02.CompareModels/Cutoff_Recovery_Accuracy_Test.pdf", width = 3.5, height = 3.5)
```

```{r fig.width=3.5, fig.height=3.5}
ggplot(cutoffList[Dataset %in% c("Validation")], aes(x = Recovery * 100, y = Accuracy * 100, colour = Model)) + 
  geom_line() + 
  theme_bw(base_size = 15) + 
  scale_x_reverse() + 
  labs(x = "Recovery (%)", y = "Accuracy (%)", title = "Validation set") + 
  theme(legend.position = "top") + 
  geom_point(data = cutoffList[Dataset %in% c("Validation") & Cutoff %in% c(c(7)/10)]) +
  geom_text(data = cutoffList[Dataset %in% c("Validation") & Cutoff %in% c(c(7)/10)], aes(x = 25, y = seq(73, 88, 3), label = L)) + 
  scale_color_brewer(palette = "Dark2") + 
  lims(y = c(70, 100)) + 
  guides(colour = "none")
ggsave("analysis/03.MachineLearning/Version7/02.Modeling/01.RF/02.CompareModels/Cutoff_Recovery_Accuracy_Validation.pdf", width = 3.5, height = 3.5)
```








